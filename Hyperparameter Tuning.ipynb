{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ec30289",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "43244e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error,  mean_squared_error\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017211d7",
   "metadata": {},
   "source": [
    "In this toy example we will look at a GradientBoostingRegressor and LinearRegression (both implemented in `sklearn`). We will use RepeatedKFold cross validation. The metric we are using for our scoring is `neg_mean_absolute_error`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7f6655ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length1</th>\n",
       "      <th>Length3</th>\n",
       "      <th>Species_Bream</th>\n",
       "      <th>Species_Parkki</th>\n",
       "      <th>Species_Perch</th>\n",
       "      <th>Species_Pike</th>\n",
       "      <th>Species_Roach</th>\n",
       "      <th>Species_Smelt</th>\n",
       "      <th>Species_Whitefish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>290.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>430.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>700.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>38.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight  Length1  Length3  Species_Bream  Species_Parkki  Species_Perch  \\\n",
       "0   290.0     24.0     29.2              0               0              0   \n",
       "1   430.0     26.5     34.0              1               0              0   \n",
       "2   700.0     34.0     38.3              0               0              1   \n",
       "3   500.0     42.0     48.0              0               0              0   \n",
       "4   110.0     19.0     22.5              0               0              1   \n",
       "\n",
       "   Species_Pike  Species_Roach  Species_Smelt  Species_Whitefish  \n",
       "0             0              1              0                  0  \n",
       "1             0              0              0                  0  \n",
       "2             0              0              0                  0  \n",
       "3             1              0              0                  0  \n",
       "4             0              0              0                  0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "40e27599",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "649361d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y =  data[:, 1:], data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4628e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4a1a65fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gb = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ce669449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search space\n",
    "num_estimators = [100, 500, 1000]\n",
    "learn_rates = [0.02, 0.05, 0.1, 0.2]\n",
    "max_depths = [1, 2, 5]\n",
    "min_samples_leaf = [5,10]\n",
    "min_samples_split = [5,10]\n",
    "space_gb = {'n_estimators': num_estimators,\n",
    "              'learning_rate': learn_rates,\n",
    "              'max_depth': max_depths,\n",
    "              'min_samples_leaf': min_samples_leaf,\n",
    "              'min_samples_split': min_samples_split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "064772a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(model_gb, space_gb, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "13c3e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_gb = search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "32b424b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -67.80347126549573\n",
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 1, 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "print('Best Score: %s' % result_gb.best_score_)\n",
    "print('Best Hyperparameters: %s' % result_gb.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89469167",
   "metadata": {},
   "source": [
    "In a real project we might have some rival models here, and we would compare them at this stage and choose the best one. Let's consider Linear Regression (this could be thought of as our baseline).\n",
    "The only parameter we have is 'fit_intercept', almost certaintly we do want to fit an intercept, but just for this toy example we will search over this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a54194a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -76.94888187660814\n",
      "Best Hyperparameters: {'fit_intercept': True}\n"
     ]
    }
   ],
   "source": [
    "model_lr = LinearRegression()\n",
    "space_lr = {'fit_intercept':[True, False]}\n",
    "search = GridSearchCV(model_lr, space_lr, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv)\n",
    "result_lr = search.fit(X,y)\n",
    "print('Best Score: %s' % result_lr.best_score_)\n",
    "print('Best Hyperparameters: %s' % result_lr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8498ef8e",
   "metadata": {},
   "source": [
    "# Choose final model\n",
    "\n",
    "For the final model we will use GradientBoostingRegressor with the best hyperparameters: `{'learning_rate': 0.2, 'max_depth': 1, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 500}`.\n",
    "\n",
    "At this stage we can see how this model (GradientBoostingRegressor with the above hyperparameters) performs on the holdout dataset. The metrics here are the metrics we would report to stakeholders. These are unbiased metrics because the holdout dataset has not been used in any of the process so far (where the best_score above is a biased estimate because it is (implicitly) using information from across the training set when the tuning is carried out).\n",
    "\n",
    "It is **absolutely crucial** at this stage that we do not do anymore tuning based on the this otherwise we will bias this estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fcad7393",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')\n",
    "test_data = test.values\n",
    "X, y =  test_data[:, 1:], test_data[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fb8bd92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the statistics we would report to stakeholders: \n",
      "Final GBRegressor: 0.9463130239173201, MAE: 39.778168094240016, MSE: 7388.717629847771\n"
     ]
    }
   ],
   "source": [
    "best_model = result_gb.best_estimator_\n",
    "y_pred = best_model.predict(X)\n",
    "R2 = r2_score(y, y_pred)\n",
    "MSE = mean_squared_error(y, y_pred)\n",
    "MAE = mean_absolute_error(y, y_pred)\n",
    "print(\"These are the statistics we would report to stakeholders: \")\n",
    "print(\"Final GBRegressor: R-squared: {}, MAE: {}, MSE: {}\".format(R2, MAE, MSE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d7d074",
   "metadata": {},
   "source": [
    "We can now train the final model on ALL of the data (this is done in another notebook)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('3.10.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ce83677e8e2d5603e58c7575ce9a64c96b6f08ebcc7c21f0772777de1c925f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
